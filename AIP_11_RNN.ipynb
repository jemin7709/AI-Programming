{"cells":[{"cell_type":"markdown","metadata":{"id":"TDOHLpfldh2L"},"source":["**Sentiment Analysis using RNN models**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":930,"status":"ok","timestamp":1668673118497,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"YA-1VojEdabb","outputId":"ef869a0b-03b5-4db5-fd18-8048a1819101"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords \n","from collections import Counter\n","import string\n","import re\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"A_5UtRWzwOq8"},"source":["**Dataset loading**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3667,"status":"ok","timestamp":1668673122160,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"cDHzi04bdl2P","outputId":"1dfe17b4-4d0d-46ab-b39a-fa0e3ba2f876"},"outputs":[],"source":["#구글 드라이브 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#zip 파일 현재 폴더로 복사, 중간 부분은 파일명에 따라 변경 필요\n","!cp '/content/drive/MyDrive/IMDB Dataset.csv.zip' ./"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22246,"status":"ok","timestamp":1668673144400,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"U9OMOr-vmXiT","outputId":"fc38ec7c-4e1e-4e7b-a61c-214e72cb854a"},"outputs":[],"source":["#압축 해제\n","!unzip 'IMDB Dataset.csv.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":813,"status":"ok","timestamp":1668673145209,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"vXiBe_7dmqZp","outputId":"a8f688c1-8541-41c4-ee66-80d8dee7d748"},"outputs":[],"source":["is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":909,"status":"ok","timestamp":1668673146116,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"kF_-x0R9mw_q","outputId":"e46a8e52-5047-44c1-8666-de2d30d967c7"},"outputs":[],"source":["#구현 필요\n","base_csv = 'IMDB Dataset.csv'\n","df = pd.read_csv(base_csv)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"JtPf72_6wTlm"},"source":["**Pre-process the dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668673146117,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"_M7nWpEsm1Aj","outputId":"fbcf7965-2cc3-4c40-d94a-0e578bda70d0"},"outputs":[],"source":["#구현 필요\n","x, y = df['review'].values, df['sentiment'].values\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n","print(f'shape of train data is {x_train.shape}')\n","print(f'shape of test data is {x_test.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668673146117,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"R2PtZ0hUnDgS"},"outputs":[],"source":["def preprocess_string(s):\n","    # Remove all non-word characters (everything except numbers and letters)\n","    s = re.sub(r\"[^\\w\\s]\", '', s)\n","    # Replace all runs of whitespaces with no space\n","    s = re.sub(r\"\\s+\", '', s)\n","    # replace digits with no space\n","    s = re.sub(r\"\\d\", '', s)\n","\n","    return s\n","\n","def tockenize(x_train,y_train,x_val,y_val):\n","    word_list = []\n","\n","    stop_words = set(stopwords.words('english')) \n","    for sent in x_train:\n","        for word in sent.lower().split():\n","            word = preprocess_string(word)\n","            if word not in stop_words and word != '':\n","                word_list.append(word)\n","  \n","    corpus = Counter(word_list)\n","    # sorting on the basis of most common words\n","    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n","    # creating a dict\n","    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n","    \n","    # tockenize\n","    final_list_train,final_list_test = [],[]\n","    for sent in x_train:\n","            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n","                                     if preprocess_string(word) in onehot_dict.keys()])\n","    for sent in x_val:\n","            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n","                                    if preprocess_string(word) in onehot_dict.keys()])\n","            \n","    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n","    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n","    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82621,"status":"ok","timestamp":1668673228734,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"_Ccbdr5IomDb","outputId":"298e3e80-b091-4c38-f4cd-fec1fb3a06eb"},"outputs":[],"source":["#구현 필요\n","x_train, y_train, x_test, y_test, vocab = tockenize(x_train, y_train, x_test, y_test)\n","print(f'Length of vocabulary is {len(vocab)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668673228735,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"NYv719ZFopKD","outputId":"1bdb80d9-7912-4e22-c6b0-d03162512212"},"outputs":[],"source":["rev_len = [len(i) for i in x_train]\n","pd.Series(rev_len).hist()\n","plt.show()\n","pd.Series(rev_len).describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1104,"status":"ok","timestamp":1668673229833,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"jRyJW2jBpURd"},"outputs":[],"source":["def padding_(sentences, seq_len):\n","    features = np.zeros((len(sentences), seq_len),dtype=int)\n","    for ii, review in enumerate(sentences):\n","        if len(review) != 0:\n","            features[ii, -len(review):] = np.array(review)[:seq_len]\n","    return features\n","\n","#구현 필요\n","x_train_pad = padding_(x_train, 200)\n","x_test_pad = padding_(x_test, 200) "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1668673229834,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"HAlTx-GwpnEz"},"outputs":[],"source":["#구현 필요\n","\n","# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n","test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n","# dataloaders\n","batch_size = 50\n","\n","# make sure to SHUFFLE your data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668673229834,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"qKtc7tXGpxCS","outputId":"79fd7d96-d6ca-44e7-c707-87715102ee16"},"outputs":[],"source":["# obtain one batch of training data\n","dataiter = iter(train_loader)\n","sample_x, sample_y = next(dataiter)\n","\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print('Sample input: \\n', sample_y)"]},{"cell_type":"markdown","metadata":{"id":"t6KGQ05Twx2r"},"source":["**GRU model code**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668673229834,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"FwfDenLCp01j"},"outputs":[],"source":["class GRU_model(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, device):\n","        super(GRU_model, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        self.device = device\n","\n","        #구현 필요\n","        self.embd = nn.Embedding(n_vocab, embed_dim)\n","        self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n","        self.out = nn.Linear(self.hidden_dim, n_classes)\n","\n","    def forward(self, x):\n","        #구현 필요\n","        x = self.embd(x)\n","        h_0 = self._init_state(batch_size=x.size(0))# 첫번째 히든 스테이트를 0벡터로 초기화\n","        x, _ = self.gru(x, h_0)# GRU의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n","        h_t = x[:, -1, :]# (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n","        logit = self.out(h_t)# (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n","        return logit\n","\n","    def _init_state(self, batch_size):\n","        #구현 필요\n","        new_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n","        return new_state"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3119,"status":"ok","timestamp":1668673232949,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"rISdhnCDrYr1"},"outputs":[],"source":["n_layers = 1\n","vocab_size = len(vocab) + 1  # extra 1 for <pad>\n","hidden_dim = 128\n","embed_dim = 100\n","n_classes = 2\n","\n","#구현 필요\n","model = GRU_model(n_layers, hidden_dim, vocab_size, embed_dim, n_classes, device).to(device)"]},{"cell_type":"markdown","metadata":{"id":"V02dcuLjw2hV"},"source":["**Train and evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1668673232950,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"i-CcnIS7s8H7"},"outputs":[],"source":["def train(model, criterion, optimizer, data_loader):\n","    model.train()\n","    train_loss = 0\n","    for i, (x, y) in enumerate(data_loader):\n","        x, y = x.to(device), y.to(device)\n","        \n","        optimizer.zero_grad()\n","        logit = model(x)\n","        loss = criterion(logit, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * x.size(0)\n","      \n","    return train_loss / len(data_loader.dataset)\n","\n","def evaluate(model, data_loader):\n","    model.eval()\n","    corrects, total_loss = 0, 0\n","    for i, (x, y) in enumerate(data_loader):\n","        x, y = x.to(device), y.to(device)\n","\n","        logit = model(x)\n","        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n","    size = len(data_loader.dataset)\n","    \n","    avg_accuracy = 100.0 * corrects / size\n","    return avg_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44564,"status":"ok","timestamp":1668673277492,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"LFdNDdr5sBXd","outputId":"f2ff086d-87ba-4b3e-ff10-f112c5587e46"},"outputs":[],"source":["num_epochs = 10\n","lr = 0.001\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","for e in range(1, num_epochs+1):\n","    #구현 필요\n","    train_loss = train(model, criterion, optimizer, train_loader)\n","    test_accuracy = evaluate(model, test_loader)\n","    print(\"[Epoch: %2d] train loss : %5.2f | test accuracy : %5.2f\" % (e, train_loss, test_accuracy))"]},{"cell_type":"markdown","metadata":{"id":"gko6X5-Yw-XM"},"source":["**LSTM model code**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668673277493,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"GnvuLbEKvRaO"},"outputs":[],"source":["class LSTM_model(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, device):\n","        super(LSTM_model, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        self.device = device\n","\n","        #구현 필요\n","        self.embed = nn.Embedding(n_vocab, embed_dim)\n","        self.lstm = nn.LSTM(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n","        self.out = nn.Linear(self.hidden_dim, n_classes)\n","    def forward(self, x):\n","        #구현 필요\n","        x = self.embed(x)\n","        h_0 = self._init_state(batch_size=x.size(0))# 첫번째 히든 스테이트를 0벡터로 초기화\n","        x, _ = self.lstm(x, h_0)# LSTM의 리턴값 또한 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n","        h_t = x[:, -1, :]# (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n","        logit = self.out(h_t)# (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n","        return logit\n","\n","    def _init_state(self, batch_size):\n","        #구현 필요\n","        new_cell_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n","        new_hidden_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n","        return (new_hidden_state, new_cell_state)"]},{"cell_type":"markdown","metadata":{"id":"bt0oCIHKxryU"},"source":["**LSTM training and evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56317,"status":"ok","timestamp":1668673333806,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"QadaToSExn_-","outputId":"a947216c-21e5-4652-bb5f-1bd626895647"},"outputs":[],"source":["#구현 필요\n","model = LSTM_model(n_layers, hidden_dim, vocab_size, embed_dim, n_classes, device).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","for e in range(1, num_epochs+1):\n","    #구현 필요\n","    train_loss = train(model, criterion, optimizer, train_loader)\n","    test_accuracy = evaluate(model, test_loader)\n","    print(\"[Epoch: %2d] train loss : %5.2f | test accuracy : %5.2f\" % (e, train_loss, test_accuracy))"]},{"cell_type":"markdown","metadata":{"id":"KiJVBRbsyVWO"},"source":["**Vanilla RNN model code**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1668673333806,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"NtHx26FZxxyU"},"outputs":[],"source":["class RNN_model(nn.Module):\n","    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, device):\n","        super(RNN_model, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        self.device = device\n","\n","        #구현 필요\n","        self.embed = nn.Embedding(n_vocab, embed_dim)\n","        self.rnn = nn.RNN(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n","        self.out = nn.Linear(self.hidden_dim, n_classes)\n","    def forward(self, x):\n","        #구현 필요\n","        x = self.embed(x)\n","        h_0 = self._init_state(batch_size=x.size(0))# 첫번째 히든 스테이트를 0벡터로 초기화\n","        x, _ = self.rnn(x, h_0)# RNN의 리턴값은 (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n","        h_t = x[:, -1, :]# (배치 크기, 은닉 상태의 크기)의 텐서로 크기가 변경됨. 즉, 마지막 time-step의 은닉 상태만 가져온다.\n","        logit = self.out(h_t)# (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n","        return logit\n","\n","    def _init_state(self, batch_size):\n","        #구현 필요        \n","        new_state = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n","        return new_state"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30658,"status":"ok","timestamp":1668673364440,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"vsOZFxmwygdV","outputId":"c3e5335f-dd6f-43bd-9feb-797236d733e1"},"outputs":[],"source":["#구현 필요\n","model = RNN_model(n_layers, hidden_dim, vocab_size, embed_dim, n_classes, device).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","for e in range(1, num_epochs+1):\n","    #구현 필요\n","    train_loss = train(model, criterion, optimizer, train_loader)\n","    test_accuracy = evaluate(model, test_loader)\n","\n","    print(\"[Epoch: %2d] train loss : %5.2f | test accuracy : %5.2f\" % (e, train_loss, test_accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1668673364440,"user":{"displayName":"박재민","userId":"00682385399829149418"},"user_tz":-540},"id":"1JnTb4N5ylAF"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":0}
